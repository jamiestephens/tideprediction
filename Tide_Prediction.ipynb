{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "I5MC6b2WqVxy",
        "h4WbtKhC6xgk",
        "AJJc0ddBbJsJ",
        "Ijh715HMtpc1",
        "7PiyAfzZ_CA7",
        "8cwOQ4mxxIRX",
        "oWfD5MI8sPgd"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMWTvC8Cm/3DuSwKmaHCMhH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jstephens/tideprediction/blob/main/Tide_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry41BGUUlVWd"
      },
      "source": [
        "# Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx28FbEqpxLC",
        "outputId": "7f8b0db3-bebc-40ca-f85c-6f59acf52f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bokeh.io import show\n",
        "from bokeh.models import ColumnDataSource, Range1d\n",
        "from bokeh.plotting import figure, output_notebook, show\n",
        "from bokeh.models import DatetimeTickFormatter, DatetimeAxis\n",
        "from bokeh.models import HoverTool\n",
        "from bokeh.models import FixedTicker\n",
        "from bokeh.embed import components\n",
        "from bokeh.embed import autoload_static\n",
        "output_notebook()\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import xgboost as xgb\n",
        "import datetime\n",
        "import joblib\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "from tensorflow.keras import backend as K\n",
        "from keras_tuner import RandomSearch\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kswjSJarloAr"
      },
      "source": [
        "# Data Load and Initial Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cmOSCzoipymK"
      },
      "outputs": [],
      "source": [
        "X_train = np.load('drive/MyDrive/source/X_train_surge_new.npz')\n",
        "X_test = np.load('drive/MyDrive/source/X_test_surge_new.npz')\n",
        "Y_train = pd.read_csv('drive/MyDrive/source/Y_train_surge.csv',index_col = 'id_sequence')\n",
        "\n",
        "df_X_test = pd.DataFrame.from_dict({item: X_test[item] for item in X_test.files}, orient='index').T.set_index('id_sequence')\n",
        "df_X_train = pd.DataFrame.from_dict({item: X_train[item] for item in X_train.files}, orient='index').T.set_index('id_sequence')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n1qRJKNxi6Bi"
      },
      "outputs": [],
      "source": [
        "def timestamp_to_datetime(timestamp):\n",
        "    return pd.to_datetime('1970-01-01') + pd.to_timedelta(timestamp, unit='s')\n",
        "\n",
        "df_X_train['t_slp'] = df_X_train['t_slp'].apply(lambda x: np.array([timestamp_to_datetime(t) for t in x]))\n",
        "df_X_train['t_surge1_input'] = df_X_train['t_surge1_input'].apply(lambda x: np.array([timestamp_to_datetime(t) for t in x]))\n",
        "df_X_train['t_surge2_input'] = df_X_train['t_surge2_input'].apply(lambda x: np.array([timestamp_to_datetime(t) for t in x]))\n",
        "df_X_train['t_surge1_output'] = df_X_train['t_surge1_output'].apply(lambda x: np.array([timestamp_to_datetime(t) for t in x]))\n",
        "df_X_train['t_surge2_output'] = df_X_train['t_surge2_output'].apply(lambda x: np.array([timestamp_to_datetime(t) for t in x]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_train = df_X_train.tail(500)\n",
        "Y_train = Y_train.tail(500)"
      ],
      "metadata": {
        "id": "6y1nW34VtE-E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional: Input EDA"
      ],
      "metadata": {
        "id": "I5MC6b2WqVxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LCS7fxUVc5dp",
        "outputId": "eb292a71-8efd-4c99-fff8-8b3e7e0066a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                         t_slp  \\\n",
              "id_sequence                                                      \n",
              "4600         [2002-03-27 12:00:00, 2002-03-27 15:00:16, 200...   \n",
              "4601         [2002-03-28 12:00:00, 2002-03-28 15:00:16, 200...   \n",
              "4602         [2002-03-29 12:00:00, 2002-03-29 15:00:16, 200...   \n",
              "4603         [2002-03-30 15:00:16, 2002-03-30 17:59:28, 200...   \n",
              "4604         [2002-03-31 15:00:16, 2002-03-31 17:59:28, 200...   \n",
              "...                                                        ...   \n",
              "5595         [2010-10-19 08:59:44, 2010-10-19 11:58:56, 201...   \n",
              "5596         [2010-10-20 08:59:44, 2010-10-20 12:01:04, 201...   \n",
              "5597         [2010-10-21 08:59:44, 2010-10-21 11:58:56, 201...   \n",
              "5598         [2010-10-22 08:59:44, 2010-10-22 12:01:04, 201...   \n",
              "5599         [2010-10-23 11:58:56, 2010-10-23 15:00:16, 201...   \n",
              "\n",
              "                                                           slp  \\\n",
              "id_sequence                                                      \n",
              "4600         [[[102326.13, 102259.13, 102183.13, 102098.13,...   \n",
              "4601         [[[101650.03, 101598.03, 101572.03, 101555.03,...   \n",
              "4602         [[[101207.48, 101035.48, 100907.48, 100831.48,...   \n",
              "4603         [[[102146.62, 102047.62, 101940.62, 101824.62,...   \n",
              "4604         [[[102549.04, 102471.04, 102387.04, 102296.04,...   \n",
              "...                                                        ...   \n",
              "5595         [[[101470.0, 101486.0, 101501.0, 101517.0, 101...   \n",
              "5596         [[[101663.87, 101650.87, 101641.87, 101635.87,...   \n",
              "5597         [[[101876.15, 101838.15, 101801.15, 101765.15,...   \n",
              "5598         [[[102152.04, 102120.04, 102085.04, 102047.04,...   \n",
              "5599         [[[102387.97, 102371.97, 102349.97, 102320.97,...   \n",
              "\n",
              "                                                t_surge1_input  \\\n",
              "id_sequence                                                      \n",
              "4600         [2002-03-27 00:00:00, 2002-03-27 12:59:44, 200...   \n",
              "4601         [2002-03-28 00:59:44, 2002-03-28 14:00:32, 200...   \n",
              "4602         [2002-03-29 01:59:28, 2002-03-29 15:00:16, 200...   \n",
              "4603         [2002-03-30 03:00:16, 2002-03-30 15:00:16, 200...   \n",
              "4604         [2002-03-31 04:00:00, 2002-03-31 16:00:00, 200...   \n",
              "...                                                        ...   \n",
              "5595         [2010-10-18 23:00:16, 2010-10-19 10:59:12, 201...   \n",
              "5596         [2010-10-20 00:00:00, 2010-10-20 12:01:04, 201...   \n",
              "5597         [2010-10-21 00:00:00, 2010-10-21 13:00:48, 201...   \n",
              "5598         [2010-10-22 00:00:00, 2010-10-22 13:00:48, 201...   \n",
              "5599         [2010-10-23 00:59:44, 2010-10-23 14:00:32, 201...   \n",
              "\n",
              "                                                  surge1_input  \\\n",
              "id_sequence                                                      \n",
              "4600         [0.19478741, -0.0029626957, 0.2014908, 0.09088...   \n",
              "4601         [0.2014908, 0.09088481, -0.023072876, 0.134456...   \n",
              "4602         [-0.023072876, 0.13445687, 0.054016147, 0.1210...   \n",
              "4603         [0.054016147, 0.12105008, 0.04060936, 0.204842...   \n",
              "4604         [0.04060936, 0.2048425, 0.28863493, 0.2014908,...   \n",
              "...                                                        ...   \n",
              "5595         [1.9376696, 1.6092033, 0.86177504, 1.2974956, ...   \n",
              "5596         [0.86177504, 1.2974956, 0.50984687, 0.87518185...   \n",
              "5597         [0.50984687, 0.87518185, 1.8505255, 1.193593, ...   \n",
              "5598         [1.8505255, 1.193593, 1.3980465, 1.7801399, 1....   \n",
              "5599         [1.3980465, 1.7801399, 1.4516736, 1.2204065, 0...   \n",
              "\n",
              "                                                t_surge2_input  \\\n",
              "id_sequence                                                      \n",
              "4600         [2002-03-27 01:59:28, 2002-03-27 15:00:16, 200...   \n",
              "4601         [2002-03-28 03:00:16, 2002-03-28 15:00:16, 200...   \n",
              "4602         [2002-03-29 04:00:00, 2002-03-29 16:00:00, 200...   \n",
              "4603         [2002-03-30 04:00:00, 2002-03-30 16:59:44, 200...   \n",
              "4604         [2002-03-31 04:59:44, 2002-03-31 16:59:44, 200...   \n",
              "...                                                        ...   \n",
              "5595         [2010-10-19 00:59:44, 2010-10-19 13:00:48, 201...   \n",
              "5596         [2010-10-20 01:59:28, 2010-10-20 14:00:32, 201...   \n",
              "5597         [2010-10-21 01:59:28, 2010-10-21 14:00:32, 201...   \n",
              "5598         [2010-10-22 02:59:12, 2010-10-22 15:00:16, 201...   \n",
              "5599         [2010-10-23 02:59:12, 2010-10-23 15:00:16, 201...   \n",
              "\n",
              "                                                  surge2_input  \\\n",
              "id_sequence                                                      \n",
              "4600         [-1.0178498, -0.5484413, -0.3640308, 0.6669915...   \n",
              "4601         [-0.3640308, 0.6669915, 0.029937062, 0.5831685...   \n",
              "4602         [0.029937062, 0.58316857, 0.24787673, 0.138906...   \n",
              "4603         [0.24787673, 0.1389069, 0.3233174, 0.54963934,...   \n",
              "4604         [0.3233174, 0.54963934, 0.7172853, 0.4909633, ...   \n",
              "...                                                        ...   \n",
              "5595         [0.021554768, 0.62508005, 0.39037576, 0.457434...   \n",
              "5596         [0.39037576, 0.45743412, 0.28140593, 0.4322872...   \n",
              "5597         [0.28140593, 0.43228725, 0.15567149, 0.2478767...   \n",
              "5598         [0.15567149, 0.24787673, 0.41552263, 0.5412571...   \n",
              "5599         [0.41552263, 0.5412571, 0.75919676, 0.88493115...   \n",
              "\n",
              "                                               t_surge1_output  \\\n",
              "id_sequence                                                      \n",
              "4600         [2002-04-01 04:00:00, 2002-04-01 16:59:44, 200...   \n",
              "4601         [2002-04-02 04:59:44, 2002-04-02 16:59:44, 200...   \n",
              "4602         [2002-04-03 04:59:44, 2002-04-03 16:59:44, 200...   \n",
              "4603         [2002-04-04 06:00:32, 2002-04-04 17:59:28, 200...   \n",
              "4604         [2002-04-05 07:00:16, 2002-04-05 19:00:16, 200...   \n",
              "...                                                        ...   \n",
              "5595         [2010-10-24 01:59:28, 2010-10-24 15:00:16, 201...   \n",
              "5596         [2010-10-25 01:59:28, 2010-10-25 15:00:16, 201...   \n",
              "5597         [2010-10-26 02:59:12, 2010-10-26 16:00:00, 201...   \n",
              "5598         [2010-10-27 04:01:04, 2010-10-27 16:00:00, 201...   \n",
              "5599         [2010-10-28 05:00:48, 2010-10-28 16:59:44, 201...   \n",
              "\n",
              "                                               t_surge2_output  \n",
              "id_sequence                                                     \n",
              "4600         [2002-04-01 06:00:32, 2002-04-01 17:59:28, 200...  \n",
              "4601         [2002-04-02 07:00:16, 2002-04-02 19:00:16, 200...  \n",
              "4602         [2002-04-03 07:00:16, 2002-04-03 20:00:00, 200...  \n",
              "4603         [2002-04-04 08:59:44, 2002-04-04 20:59:44, 200...  \n",
              "4604         [2002-04-05 09:59:28, 2002-04-05 23:00:16, 200...  \n",
              "...                                                        ...  \n",
              "5595         [2010-10-24 03:58:56, 2010-10-24 16:00:00, 201...  \n",
              "5596         [2010-10-25 04:01:04, 2010-10-25 16:00:00, 201...  \n",
              "5597         [2010-10-26 05:00:48, 2010-10-26 16:59:44, 201...  \n",
              "5598         [2010-10-27 05:00:48, 2010-10-27 17:59:28, 201...  \n",
              "5599         [2010-10-28 06:00:32, 2010-10-28 18:59:12, 201...  \n",
              "\n",
              "[1000 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03d5ce11-0a0c-4e72-b903-e9f65bc1150f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t_slp</th>\n",
              "      <th>slp</th>\n",
              "      <th>t_surge1_input</th>\n",
              "      <th>surge1_input</th>\n",
              "      <th>t_surge2_input</th>\n",
              "      <th>surge2_input</th>\n",
              "      <th>t_surge1_output</th>\n",
              "      <th>t_surge2_output</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>[2002-03-27 12:00:00, 2002-03-27 15:00:16, 200...</td>\n",
              "      <td>[[[102326.13, 102259.13, 102183.13, 102098.13,...</td>\n",
              "      <td>[2002-03-27 00:00:00, 2002-03-27 12:59:44, 200...</td>\n",
              "      <td>[0.19478741, -0.0029626957, 0.2014908, 0.09088...</td>\n",
              "      <td>[2002-03-27 01:59:28, 2002-03-27 15:00:16, 200...</td>\n",
              "      <td>[-1.0178498, -0.5484413, -0.3640308, 0.6669915...</td>\n",
              "      <td>[2002-04-01 04:00:00, 2002-04-01 16:59:44, 200...</td>\n",
              "      <td>[2002-04-01 06:00:32, 2002-04-01 17:59:28, 200...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4601</th>\n",
              "      <td>[2002-03-28 12:00:00, 2002-03-28 15:00:16, 200...</td>\n",
              "      <td>[[[101650.03, 101598.03, 101572.03, 101555.03,...</td>\n",
              "      <td>[2002-03-28 00:59:44, 2002-03-28 14:00:32, 200...</td>\n",
              "      <td>[0.2014908, 0.09088481, -0.023072876, 0.134456...</td>\n",
              "      <td>[2002-03-28 03:00:16, 2002-03-28 15:00:16, 200...</td>\n",
              "      <td>[-0.3640308, 0.6669915, 0.029937062, 0.5831685...</td>\n",
              "      <td>[2002-04-02 04:59:44, 2002-04-02 16:59:44, 200...</td>\n",
              "      <td>[2002-04-02 07:00:16, 2002-04-02 19:00:16, 200...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4602</th>\n",
              "      <td>[2002-03-29 12:00:00, 2002-03-29 15:00:16, 200...</td>\n",
              "      <td>[[[101207.48, 101035.48, 100907.48, 100831.48,...</td>\n",
              "      <td>[2002-03-29 01:59:28, 2002-03-29 15:00:16, 200...</td>\n",
              "      <td>[-0.023072876, 0.13445687, 0.054016147, 0.1210...</td>\n",
              "      <td>[2002-03-29 04:00:00, 2002-03-29 16:00:00, 200...</td>\n",
              "      <td>[0.029937062, 0.58316857, 0.24787673, 0.138906...</td>\n",
              "      <td>[2002-04-03 04:59:44, 2002-04-03 16:59:44, 200...</td>\n",
              "      <td>[2002-04-03 07:00:16, 2002-04-03 20:00:00, 200...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4603</th>\n",
              "      <td>[2002-03-30 15:00:16, 2002-03-30 17:59:28, 200...</td>\n",
              "      <td>[[[102146.62, 102047.62, 101940.62, 101824.62,...</td>\n",
              "      <td>[2002-03-30 03:00:16, 2002-03-30 15:00:16, 200...</td>\n",
              "      <td>[0.054016147, 0.12105008, 0.04060936, 0.204842...</td>\n",
              "      <td>[2002-03-30 04:00:00, 2002-03-30 16:59:44, 200...</td>\n",
              "      <td>[0.24787673, 0.1389069, 0.3233174, 0.54963934,...</td>\n",
              "      <td>[2002-04-04 06:00:32, 2002-04-04 17:59:28, 200...</td>\n",
              "      <td>[2002-04-04 08:59:44, 2002-04-04 20:59:44, 200...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4604</th>\n",
              "      <td>[2002-03-31 15:00:16, 2002-03-31 17:59:28, 200...</td>\n",
              "      <td>[[[102549.04, 102471.04, 102387.04, 102296.04,...</td>\n",
              "      <td>[2002-03-31 04:00:00, 2002-03-31 16:00:00, 200...</td>\n",
              "      <td>[0.04060936, 0.2048425, 0.28863493, 0.2014908,...</td>\n",
              "      <td>[2002-03-31 04:59:44, 2002-03-31 16:59:44, 200...</td>\n",
              "      <td>[0.3233174, 0.54963934, 0.7172853, 0.4909633, ...</td>\n",
              "      <td>[2002-04-05 07:00:16, 2002-04-05 19:00:16, 200...</td>\n",
              "      <td>[2002-04-05 09:59:28, 2002-04-05 23:00:16, 200...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5595</th>\n",
              "      <td>[2010-10-19 08:59:44, 2010-10-19 11:58:56, 201...</td>\n",
              "      <td>[[[101470.0, 101486.0, 101501.0, 101517.0, 101...</td>\n",
              "      <td>[2010-10-18 23:00:16, 2010-10-19 10:59:12, 201...</td>\n",
              "      <td>[1.9376696, 1.6092033, 0.86177504, 1.2974956, ...</td>\n",
              "      <td>[2010-10-19 00:59:44, 2010-10-19 13:00:48, 201...</td>\n",
              "      <td>[0.021554768, 0.62508005, 0.39037576, 0.457434...</td>\n",
              "      <td>[2010-10-24 01:59:28, 2010-10-24 15:00:16, 201...</td>\n",
              "      <td>[2010-10-24 03:58:56, 2010-10-24 16:00:00, 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5596</th>\n",
              "      <td>[2010-10-20 08:59:44, 2010-10-20 12:01:04, 201...</td>\n",
              "      <td>[[[101663.87, 101650.87, 101641.87, 101635.87,...</td>\n",
              "      <td>[2010-10-20 00:00:00, 2010-10-20 12:01:04, 201...</td>\n",
              "      <td>[0.86177504, 1.2974956, 0.50984687, 0.87518185...</td>\n",
              "      <td>[2010-10-20 01:59:28, 2010-10-20 14:00:32, 201...</td>\n",
              "      <td>[0.39037576, 0.45743412, 0.28140593, 0.4322872...</td>\n",
              "      <td>[2010-10-25 01:59:28, 2010-10-25 15:00:16, 201...</td>\n",
              "      <td>[2010-10-25 04:01:04, 2010-10-25 16:00:00, 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5597</th>\n",
              "      <td>[2010-10-21 08:59:44, 2010-10-21 11:58:56, 201...</td>\n",
              "      <td>[[[101876.15, 101838.15, 101801.15, 101765.15,...</td>\n",
              "      <td>[2010-10-21 00:00:00, 2010-10-21 13:00:48, 201...</td>\n",
              "      <td>[0.50984687, 0.87518185, 1.8505255, 1.193593, ...</td>\n",
              "      <td>[2010-10-21 01:59:28, 2010-10-21 14:00:32, 201...</td>\n",
              "      <td>[0.28140593, 0.43228725, 0.15567149, 0.2478767...</td>\n",
              "      <td>[2010-10-26 02:59:12, 2010-10-26 16:00:00, 201...</td>\n",
              "      <td>[2010-10-26 05:00:48, 2010-10-26 16:59:44, 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5598</th>\n",
              "      <td>[2010-10-22 08:59:44, 2010-10-22 12:01:04, 201...</td>\n",
              "      <td>[[[102152.04, 102120.04, 102085.04, 102047.04,...</td>\n",
              "      <td>[2010-10-22 00:00:00, 2010-10-22 13:00:48, 201...</td>\n",
              "      <td>[1.8505255, 1.193593, 1.3980465, 1.7801399, 1....</td>\n",
              "      <td>[2010-10-22 02:59:12, 2010-10-22 15:00:16, 201...</td>\n",
              "      <td>[0.15567149, 0.24787673, 0.41552263, 0.5412571...</td>\n",
              "      <td>[2010-10-27 04:01:04, 2010-10-27 16:00:00, 201...</td>\n",
              "      <td>[2010-10-27 05:00:48, 2010-10-27 17:59:28, 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5599</th>\n",
              "      <td>[2010-10-23 11:58:56, 2010-10-23 15:00:16, 201...</td>\n",
              "      <td>[[[102387.97, 102371.97, 102349.97, 102320.97,...</td>\n",
              "      <td>[2010-10-23 00:59:44, 2010-10-23 14:00:32, 201...</td>\n",
              "      <td>[1.3980465, 1.7801399, 1.4516736, 1.2204065, 0...</td>\n",
              "      <td>[2010-10-23 02:59:12, 2010-10-23 15:00:16, 201...</td>\n",
              "      <td>[0.41552263, 0.5412571, 0.75919676, 0.88493115...</td>\n",
              "      <td>[2010-10-28 05:00:48, 2010-10-28 16:59:44, 201...</td>\n",
              "      <td>[2010-10-28 06:00:32, 2010-10-28 18:59:12, 201...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03d5ce11-0a0c-4e72-b903-e9f65bc1150f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-03d5ce11-0a0c-4e72-b903-e9f65bc1150f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-03d5ce11-0a0c-4e72-b903-e9f65bc1150f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty5BJEECI-H8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "76962fa7-ea9e-4f49-c241-36512efdfe97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             surge1_t0  surge1_t1  surge1_t2  surge1_t3  surge1_t4  surge1_t5  \\\n",
              "id_sequence                                                                     \n",
              "4600          0.288635   0.201491   0.214898   0.325504  -0.180603  -0.867700   \n",
              "4601          0.214898   0.325504  -0.180603  -0.867700  -0.720226  -0.230878   \n",
              "4602         -0.180603  -0.867700  -0.720226  -0.230878  -0.354891  -1.460951   \n",
              "4603         -0.720226  -0.230878  -0.354891  -1.460951  -0.750391  -0.351539   \n",
              "4604         -0.354891  -1.460951  -0.750391  -0.351539  -0.395111  -0.455442   \n",
              "...                ...        ...        ...        ...        ...        ...   \n",
              "5595          1.451674   1.220407   0.556771   1.709754   0.483033   0.533309   \n",
              "5596          0.556771   1.709754   0.483033   0.533309   1.448322   1.820360   \n",
              "5597          0.483033   0.533309   1.448322   1.820360   1.662831   1.528763   \n",
              "5598          1.448322   1.820360   1.662831   1.528763   1.284089   0.070775   \n",
              "5599          1.662831   1.528763   1.284089   0.070775   0.888589   1.545521   \n",
              "\n",
              "             surge1_t6  surge1_t7  surge1_t8  surge1_t9  surge2_t0  surge2_t1  \\\n",
              "id_sequence                                                                     \n",
              "4600         -0.720226  -0.230878  -0.354891  -1.460951   0.717285   0.490963   \n",
              "4601         -0.354891  -1.460951  -0.750391  -0.351539   0.985519   1.639338   \n",
              "4602         -0.750391  -0.351539  -0.395111  -0.455442   1.396251   1.052577   \n",
              "4603         -0.395111  -0.455442  -0.137031   0.399241   1.102871   0.843020   \n",
              "4604         -0.137031   0.399241   0.278580  -0.462145   1.681249   1.957865   \n",
              "...                ...        ...        ...        ...        ...        ...   \n",
              "5595          1.448322   1.820360   1.662831   1.528763   0.759197   0.884931   \n",
              "5596          1.662831   1.528763   1.284089   0.070775   0.298171  -0.397560   \n",
              "5597          1.284089   0.070775   0.888589   1.545521  -0.540059  -0.498148   \n",
              "5598          0.888589   1.545521   1.166779   0.653970  -0.498148  -0.405942   \n",
              "5599          1.166779   0.653970   0.409296   0.137809   0.164054   0.331700   \n",
              "\n",
              "             surge2_t2  surge2_t3  surge2_t4  surge2_t5  surge2_t6  surge2_t7  \\\n",
              "id_sequence                                                                     \n",
              "4600          0.985519   1.639338   1.396251   1.052577   1.102871   0.843020   \n",
              "4601          1.396251   1.052577   1.102871   0.843020   1.681249   1.957865   \n",
              "4602          1.102871   0.843020   1.681249   1.957865   2.469185   2.083599   \n",
              "4603          1.681249   1.957865   2.469185   2.083599   1.874042   1.521986   \n",
              "4604          2.469185   2.083599   1.874042   1.521986   1.262134   0.859784   \n",
              "...                ...        ...        ...        ...        ...        ...   \n",
              "5595          0.298171  -0.397560  -0.540059  -0.498148  -0.498148  -0.405942   \n",
              "5596         -0.540059  -0.498148  -0.498148  -0.405942   0.164054   0.331700   \n",
              "5597         -0.498148  -0.405942   0.164054   0.331700   1.052577   1.220223   \n",
              "5598          0.164054   0.331700   1.052577   1.220223   1.446545   2.670360   \n",
              "5599          1.052577   1.220223   1.446545   2.670360   2.620066   2.678742   \n",
              "\n",
              "             surge2_t8  surge2_t9  \n",
              "id_sequence                        \n",
              "4600          1.681249   1.957865  \n",
              "4601          2.469185   2.083599  \n",
              "4602          1.874042   1.521986  \n",
              "4603          1.262134   0.859784  \n",
              "4604          0.574786   0.625080  \n",
              "...                ...        ...  \n",
              "5595          0.164054   0.331700  \n",
              "5596          1.052577   1.220223  \n",
              "5597          1.446545   2.670360  \n",
              "5598          2.620066   2.678742  \n",
              "5599          1.220223   0.725668  \n",
              "\n",
              "[1000 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cc0c1e0-429b-4015-9b69-721bef569f70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>surge1_t0</th>\n",
              "      <th>surge1_t1</th>\n",
              "      <th>surge1_t2</th>\n",
              "      <th>surge1_t3</th>\n",
              "      <th>surge1_t4</th>\n",
              "      <th>surge1_t5</th>\n",
              "      <th>surge1_t6</th>\n",
              "      <th>surge1_t7</th>\n",
              "      <th>surge1_t8</th>\n",
              "      <th>surge1_t9</th>\n",
              "      <th>surge2_t0</th>\n",
              "      <th>surge2_t1</th>\n",
              "      <th>surge2_t2</th>\n",
              "      <th>surge2_t3</th>\n",
              "      <th>surge2_t4</th>\n",
              "      <th>surge2_t5</th>\n",
              "      <th>surge2_t6</th>\n",
              "      <th>surge2_t7</th>\n",
              "      <th>surge2_t8</th>\n",
              "      <th>surge2_t9</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_sequence</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>0.288635</td>\n",
              "      <td>0.201491</td>\n",
              "      <td>0.214898</td>\n",
              "      <td>0.325504</td>\n",
              "      <td>-0.180603</td>\n",
              "      <td>-0.867700</td>\n",
              "      <td>-0.720226</td>\n",
              "      <td>-0.230878</td>\n",
              "      <td>-0.354891</td>\n",
              "      <td>-1.460951</td>\n",
              "      <td>0.717285</td>\n",
              "      <td>0.490963</td>\n",
              "      <td>0.985519</td>\n",
              "      <td>1.639338</td>\n",
              "      <td>1.396251</td>\n",
              "      <td>1.052577</td>\n",
              "      <td>1.102871</td>\n",
              "      <td>0.843020</td>\n",
              "      <td>1.681249</td>\n",
              "      <td>1.957865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4601</th>\n",
              "      <td>0.214898</td>\n",
              "      <td>0.325504</td>\n",
              "      <td>-0.180603</td>\n",
              "      <td>-0.867700</td>\n",
              "      <td>-0.720226</td>\n",
              "      <td>-0.230878</td>\n",
              "      <td>-0.354891</td>\n",
              "      <td>-1.460951</td>\n",
              "      <td>-0.750391</td>\n",
              "      <td>-0.351539</td>\n",
              "      <td>0.985519</td>\n",
              "      <td>1.639338</td>\n",
              "      <td>1.396251</td>\n",
              "      <td>1.052577</td>\n",
              "      <td>1.102871</td>\n",
              "      <td>0.843020</td>\n",
              "      <td>1.681249</td>\n",
              "      <td>1.957865</td>\n",
              "      <td>2.469185</td>\n",
              "      <td>2.083599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4602</th>\n",
              "      <td>-0.180603</td>\n",
              "      <td>-0.867700</td>\n",
              "      <td>-0.720226</td>\n",
              "      <td>-0.230878</td>\n",
              "      <td>-0.354891</td>\n",
              "      <td>-1.460951</td>\n",
              "      <td>-0.750391</td>\n",
              "      <td>-0.351539</td>\n",
              "      <td>-0.395111</td>\n",
              "      <td>-0.455442</td>\n",
              "      <td>1.396251</td>\n",
              "      <td>1.052577</td>\n",
              "      <td>1.102871</td>\n",
              "      <td>0.843020</td>\n",
              "      <td>1.681249</td>\n",
              "      <td>1.957865</td>\n",
              "      <td>2.469185</td>\n",
              "      <td>2.083599</td>\n",
              "      <td>1.874042</td>\n",
              "      <td>1.521986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4603</th>\n",
              "      <td>-0.720226</td>\n",
              "      <td>-0.230878</td>\n",
              "      <td>-0.354891</td>\n",
              "      <td>-1.460951</td>\n",
              "      <td>-0.750391</td>\n",
              "      <td>-0.351539</td>\n",
              "      <td>-0.395111</td>\n",
              "      <td>-0.455442</td>\n",
              "      <td>-0.137031</td>\n",
              "      <td>0.399241</td>\n",
              "      <td>1.102871</td>\n",
              "      <td>0.843020</td>\n",
              "      <td>1.681249</td>\n",
              "      <td>1.957865</td>\n",
              "      <td>2.469185</td>\n",
              "      <td>2.083599</td>\n",
              "      <td>1.874042</td>\n",
              "      <td>1.521986</td>\n",
              "      <td>1.262134</td>\n",
              "      <td>0.859784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4604</th>\n",
              "      <td>-0.354891</td>\n",
              "      <td>-1.460951</td>\n",
              "      <td>-0.750391</td>\n",
              "      <td>-0.351539</td>\n",
              "      <td>-0.395111</td>\n",
              "      <td>-0.455442</td>\n",
              "      <td>-0.137031</td>\n",
              "      <td>0.399241</td>\n",
              "      <td>0.278580</td>\n",
              "      <td>-0.462145</td>\n",
              "      <td>1.681249</td>\n",
              "      <td>1.957865</td>\n",
              "      <td>2.469185</td>\n",
              "      <td>2.083599</td>\n",
              "      <td>1.874042</td>\n",
              "      <td>1.521986</td>\n",
              "      <td>1.262134</td>\n",
              "      <td>0.859784</td>\n",
              "      <td>0.574786</td>\n",
              "      <td>0.625080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5595</th>\n",
              "      <td>1.451674</td>\n",
              "      <td>1.220407</td>\n",
              "      <td>0.556771</td>\n",
              "      <td>1.709754</td>\n",
              "      <td>0.483033</td>\n",
              "      <td>0.533309</td>\n",
              "      <td>1.448322</td>\n",
              "      <td>1.820360</td>\n",
              "      <td>1.662831</td>\n",
              "      <td>1.528763</td>\n",
              "      <td>0.759197</td>\n",
              "      <td>0.884931</td>\n",
              "      <td>0.298171</td>\n",
              "      <td>-0.397560</td>\n",
              "      <td>-0.540059</td>\n",
              "      <td>-0.498148</td>\n",
              "      <td>-0.498148</td>\n",
              "      <td>-0.405942</td>\n",
              "      <td>0.164054</td>\n",
              "      <td>0.331700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5596</th>\n",
              "      <td>0.556771</td>\n",
              "      <td>1.709754</td>\n",
              "      <td>0.483033</td>\n",
              "      <td>0.533309</td>\n",
              "      <td>1.448322</td>\n",
              "      <td>1.820360</td>\n",
              "      <td>1.662831</td>\n",
              "      <td>1.528763</td>\n",
              "      <td>1.284089</td>\n",
              "      <td>0.070775</td>\n",
              "      <td>0.298171</td>\n",
              "      <td>-0.397560</td>\n",
              "      <td>-0.540059</td>\n",
              "      <td>-0.498148</td>\n",
              "      <td>-0.498148</td>\n",
              "      <td>-0.405942</td>\n",
              "      <td>0.164054</td>\n",
              "      <td>0.331700</td>\n",
              "      <td>1.052577</td>\n",
              "      <td>1.220223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5597</th>\n",
              "      <td>0.483033</td>\n",
              "      <td>0.533309</td>\n",
              "      <td>1.448322</td>\n",
              "      <td>1.820360</td>\n",
              "      <td>1.662831</td>\n",
              "      <td>1.528763</td>\n",
              "      <td>1.284089</td>\n",
              "      <td>0.070775</td>\n",
              "      <td>0.888589</td>\n",
              "      <td>1.545521</td>\n",
              "      <td>-0.540059</td>\n",
              "      <td>-0.498148</td>\n",
              "      <td>-0.498148</td>\n",
              "      <td>-0.405942</td>\n",
              "      <td>0.164054</td>\n",
              "      <td>0.331700</td>\n",
              "      <td>1.052577</td>\n",
              "      <td>1.220223</td>\n",
              "      <td>1.446545</td>\n",
              "      <td>2.670360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5598</th>\n",
              "      <td>1.448322</td>\n",
              "      <td>1.820360</td>\n",
              "      <td>1.662831</td>\n",
              "      <td>1.528763</td>\n",
              "      <td>1.284089</td>\n",
              "      <td>0.070775</td>\n",
              "      <td>0.888589</td>\n",
              "      <td>1.545521</td>\n",
              "      <td>1.166779</td>\n",
              "      <td>0.653970</td>\n",
              "      <td>-0.498148</td>\n",
              "      <td>-0.405942</td>\n",
              "      <td>0.164054</td>\n",
              "      <td>0.331700</td>\n",
              "      <td>1.052577</td>\n",
              "      <td>1.220223</td>\n",
              "      <td>1.446545</td>\n",
              "      <td>2.670360</td>\n",
              "      <td>2.620066</td>\n",
              "      <td>2.678742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5599</th>\n",
              "      <td>1.662831</td>\n",
              "      <td>1.528763</td>\n",
              "      <td>1.284089</td>\n",
              "      <td>0.070775</td>\n",
              "      <td>0.888589</td>\n",
              "      <td>1.545521</td>\n",
              "      <td>1.166779</td>\n",
              "      <td>0.653970</td>\n",
              "      <td>0.409296</td>\n",
              "      <td>0.137809</td>\n",
              "      <td>0.164054</td>\n",
              "      <td>0.331700</td>\n",
              "      <td>1.052577</td>\n",
              "      <td>1.220223</td>\n",
              "      <td>1.446545</td>\n",
              "      <td>2.670360</td>\n",
              "      <td>2.620066</td>\n",
              "      <td>2.678742</td>\n",
              "      <td>1.220223</td>\n",
              "      <td>0.725668</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cc0c1e0-429b-4015-9b69-721bef569f70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cc0c1e0-429b-4015-9b69-721bef569f70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cc0c1e0-429b-4015-9b69-721bef569f70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "Y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional: EDA Visualizations"
      ],
      "metadata": {
        "id": "h4WbtKhC6xgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These were used on a brief [writeup](https://jstephens.io/projects/tideprediction/) after exporting to JavaScript or .gif format."
      ],
      "metadata": {
        "id": "ZFdnW9J963a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Timestamp Graph\n",
        "\n"
      ],
      "metadata": {
        "id": "AJJc0ddBbJsJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YGcVgiae4Tm"
      },
      "outputs": [],
      "source": [
        "def timestamp_graph(df_bokeh):\n",
        "  rows = [100, 101, 102]\n",
        "  data_sources = []\n",
        "\n",
        "  for i, row in enumerate(rows):\n",
        "      df_row = pd.DataFrame(df_bokeh.iloc[row]).T\n",
        "\n",
        "      columns = ['t_slp', 't_surge1_input', 't_surge2_input', 't_surge1_output', 't_surge2_output']\n",
        "      dfs = {}\n",
        "\n",
        "      for column in columns:\n",
        "          df = pd.DataFrame(df_row[column])\n",
        "          df = df.explode(column).reset_index(drop=True)\n",
        "          dfs[column] = df\n",
        "\n",
        "      x = [15, 8, 1][i]\n",
        "      x2 = x + 2\n",
        "      x3 = x + 3\n",
        "\n",
        "      source_row = ColumnDataSource(data=dict(\n",
        "          x=pd.to_datetime(dfs['t_slp']['t_slp']),\n",
        "          y=[x] * len(dfs['t_slp']),\n",
        "          size=[10] * len(dfs['t_slp']),\n",
        "          color=[colorvar] * len(dfs['t_slp'])\n",
        "      ))\n",
        "      source2_row = ColumnDataSource(data=dict(\n",
        "          x=pd.to_datetime(dfs['t_surge1_input']['t_surge1_input']),\n",
        "          y=[x2] * len(dfs['t_surge1_input']),\n",
        "          size=[10] * len(dfs['t_surge1_input']),\n",
        "          color=[colorvar] * len(dfs['t_surge1_input'])\n",
        "      ))\n",
        "      source3_row = ColumnDataSource(data=dict(\n",
        "          x=pd.to_datetime(dfs['t_surge2_input']['t_surge2_input']),\n",
        "          y=[x3] * len(dfs['t_surge2_input']),\n",
        "          size=[10] * len(dfs['t_surge2_input']),\n",
        "          color=[colorvar] * len(dfs['t_surge2_input'])\n",
        "      ))\n",
        "      source2_pred_row = ColumnDataSource(data=dict(\n",
        "          x=pd.to_datetime(dfs['t_surge1_output']['t_surge1_output']),\n",
        "          y=[x2] * len(dfs['t_surge1_output']),\n",
        "          size=[10] * len(dfs['t_surge1_output']),\n",
        "          color=['lightgray'] * len(dfs['t_surge1_output'])\n",
        "      ))\n",
        "      source3_pred_row = ColumnDataSource(data=dict(\n",
        "          x=pd.to_datetime(dfs['t_surge2_output']['t_surge2_output']),\n",
        "          y=[x3] * len(dfs['t_surge2_output']),\n",
        "          size=[10] * len(dfs['t_surge2_output']),\n",
        "          color=['lightgray'] * len(dfs['t_surge2_output'])\n",
        "      ))\n",
        "\n",
        "      data_sources.extend([source_row, source2_row, source3_row, source2_pred_row, source3_pred_row])\n",
        "\n",
        "\n",
        "  p = figure(plot_width=800, plot_height=400, x_axis_label='Timestamp', y_axis_label='', toolbar_location=None, x_axis_type='datetime')\n",
        "\n",
        "  y_ticks = [1,2.5,3,4,8,9.5,10,11,15,16.5,17,18]\n",
        "  y_labels = ['Encoded Image Recorded','Row 102                                                               ','Surge Time, City 1','Surge Time, City 2',\n",
        "              'Encoded Image Recorded','Row 101                                                               ','Surge Time, City 1','Surge Time, City 2',\n",
        "              'Encoded Image Recorded','Row 100                                                               ','Surge Time, City 1','Surge Time, City 2']\n",
        "  p.yaxis.ticker = FixedTicker(ticks=y_ticks)\n",
        "  p.yaxis.major_label_overrides = {tick: label for tick, label in zip(y_ticks, y_labels)}\n",
        "\n",
        "  p.ygrid.grid_line_color = 'white'\n",
        "\n",
        "  sources = [\n",
        "      source_row100, source2_row100, source3_row100, source2_pred_row100, source3_pred_row100,\n",
        "      source_row101, source2_row101, source3_row101, source2_pred_row101, source3_pred_row101,\n",
        "      source_row102, source2_row102, source3_row102, source2_pred_row102, source3_pred_row102\n",
        "  ]\n",
        "\n",
        "  for source in sources:\n",
        "      p.circle('x', 'y', source=source, size='size', alpha=0.5,color='color')\n",
        "\n",
        "  p.x_range=Range1d(start=pd.Timestamp('1950-11-06 12:30:00'), end=pd.Timestamp('1950-11-18 12:30:00'))\n",
        "\n",
        "  p.y_range=Range1d(start=0, end=19)\n",
        "\n",
        "  p.xaxis.major_tick_line_color = None\n",
        "  p.xaxis.minor_tick_line_color = None\n",
        "  p.yaxis.major_tick_line_color = None\n",
        "  p.yaxis.minor_tick_line_color = None\n",
        "\n",
        "  hover = HoverTool(\n",
        "      tooltips=[\n",
        "          (\"Time\", \"@x{%F %T}\")\n",
        "      ],\n",
        "      formatters={\"@x\": \"datetime\"},\n",
        "      mode='mouse'\n",
        "  )\n",
        "  p.add_tools(hover)\n",
        "  output_notebook()\n",
        "  show(p)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bokeh = df_X_train.copy()\n",
        "timestamp_graph(df_bokeh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "WyIl_rrZlNnm",
        "outputId": "a5b2e5dc-bc17-40f6-a12d-9a9ae7cc9023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-533ab462991a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_bokeh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_X_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtimestamp_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_bokeh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-fa9fa93c7bfa>\u001b[0m in \u001b[0;36mtimestamp_graph\u001b[0;34m(df_bokeh)\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't_slp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m           \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't_slp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m           \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolorvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't_slp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       ))\n\u001b[1;32m     26\u001b[0m       source2_row = ColumnDataSource(data=dict(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'colorvar' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KROTwu5LL3lO"
      },
      "source": [
        "The plot above represents three typical rows for the X training dataset. Each row represents 5 days but will overlap with other rows temporally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GG3khjOLH_1"
      },
      "outputs": [],
      "source": [
        "script, div = components(p)\n",
        "print(div)\n",
        "print(script)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoded Image GIF"
      ],
      "metadata": {
        "id": "IbOpRsGobfpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gif(df_X_train,column):\n",
        "  # Retrieve the 40 images from the row of interest\n",
        "  images = df_X_train[column][5599]\n",
        "\n",
        "  # Create an empty list to store the image file names\n",
        "  image_files = []\n",
        "\n",
        "  # Loop over each image and save it as a file\n",
        "  for i in range(len(images)):\n",
        "      # Create the file name with a 4-digit index\n",
        "      filename = f'image_{i:04d}.png'\n",
        "      \n",
        "      # Save the image as a file\n",
        "      plt.imsave(filename, images[i], cmap='gray')\n",
        "      \n",
        "      # Add the file name to the list\n",
        "      image_files.append(filename)\n",
        "\n",
        "  # Use imageio to create the gif\n",
        "  filename = 'x_train_'+column+'.gif'\n",
        "\n",
        "  with imageio.get_writer(filename, mode='I') as writer:\n",
        "      # Loop over each image file and add it to the gif\n",
        "      for filename in image_files:\n",
        "          image = imageio.imread(filename)\n",
        "          writer.append_data(image)"
      ],
      "metadata": {
        "id": "YeOKnza6x4XD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gif(df_X_train,'slp')"
      ],
      "metadata": {
        "id": "QPoUeVnJrfAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48483157-19ca-49a5-b7a4-eddda169b9fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-71ca0dbb47c9>:25: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(filename)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Timestamp Transformations\n",
        "\n"
      ],
      "metadata": {
        "id": "yXcppPq2rjeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nth_day(timestamps):\n",
        "    first_timestamp = timestamps[0]\n",
        "    year_start = datetime.datetime(first_timestamp.year, 1, 1)\n",
        "    return int((first_timestamp - year_start).days + 1)\n",
        "\n",
        "def get_last_date(timestamps):\n",
        "    last_timestamp = timestamps[-1]\n",
        "    year_start = datetime.datetime(last_timestamp.year, 1, 1)\n",
        "    return int((last_timestamp - year_start).days + 1)\n",
        "\n",
        "def get_first_year(timestamps):\n",
        "    return timestamps[0].year\n",
        "\n",
        "def extract_hour(timestamps):\n",
        "    return np.array([pd.Timestamp(ts, unit='s').hour for ts in timestamps])"
      ],
      "metadata": {
        "id": "i9OaoUKQALo2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_train['startingdate'] = df_X_train['t_slp'].apply(lambda x: get_nth_day(x))\n",
        "df_X_train['lastdate'] = df_X_train['t_slp'].apply(lambda x: get_last_date(x))\n",
        "df_X_train['year'] = df_X_train['t_slp'].apply(lambda x: get_first_year(x))\n",
        "df_X_train['t_slp'] = df_X_train['t_slp'].apply(lambda x: extract_hour(x))\n",
        "df_X_train['t_surge1_input'] = df_X_train['t_surge1_input'].apply(lambda x: extract_hour(x))\n",
        "df_X_train['t_surge2_input'] = df_X_train['t_surge2_input'].apply(lambda x: extract_hour(x))\n",
        "df_X_train['t_surge1_output'] = df_X_train['t_surge1_output'].apply(lambda x: extract_hour(x))\n",
        "df_X_train['t_surge2_output'] = df_X_train['t_surge2_output'].apply(lambda x: extract_hour(x))"
      ],
      "metadata": {
        "id": "4oHKdrdhszn9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Calculation"
      ],
      "metadata": {
        "id": "kpdI76D3C0Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_gradients(row):\n",
        "    image_gradient = np.zeros((40, 41, 41))\n",
        "    for i in range(40):\n",
        "        image_gradient[i] = np.gradient(row[i], axis=1)\n",
        "    return image_gradient\n",
        "\n",
        "# Apply the calculate_gradients function to each row of the 'slp' column\n",
        "df_X_train['gradient'] = df_X_train['slp'].apply(calculate_gradients)"
      ],
      "metadata": {
        "id": "xHtLmzecEDS2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gif(df_X_train,'gradient')"
      ],
      "metadata": {
        "id": "KlwSt0cBFHcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Prep"
      ],
      "metadata": {
        "id": "lplIBpidhMSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling Data for RNN Use Only"
      ],
      "metadata": {
        "id": "eBRlMzdKHQDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the scaling function\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "for i, row in df_X_train['slp'].items():\n",
        "    # Scale each numpy array in the row\n",
        "    scaled_array = np.array([scaler.fit_transform(arr) for arr in row])\n",
        "    \n",
        "    # Update the dataframe column with the scaled values\n",
        "    df_X_train.at[i, 'slp'] = scaled_array"
      ],
      "metadata": {
        "id": "iB91UhAMHPk9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler() \n",
        "\n",
        "for i, row in df_X_train['gradient'].items():\n",
        "    # Scale each numpy array in the row\n",
        "    scaled_array = np.array([scaler.fit_transform(arr) for arr in row])\n",
        "    \n",
        "    # Update the dataframe column with the scaled values\n",
        "    df_X_train.at[i, 'gradient'] = scaled_array"
      ],
      "metadata": {
        "id": "toZGRMjNMUhm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_train['slp'] = df_X_train['slp'].apply(lambda arr: np.concatenate(arr).ravel())\n",
        "df_X_train['gradient'] = df_X_train['gradient'].apply(lambda arr: np.concatenate(arr).ravel())"
      ],
      "metadata": {
        "id": "FfykbIGPsoL6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_array(row):\n",
        "    new_row = []\n",
        "    for col in row:\n",
        "        if isinstance(col, np.ndarray):\n",
        "            new_row.extend(col.ravel())\n",
        "        else:\n",
        "            new_row.append(col)\n",
        "    return pd.Series(new_row)"
      ],
      "metadata": {
        "id": "6z8Y7rcAGdTB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Model Dataset Prep"
      ],
      "metadata": {
        "id": "hEsIWG1kRLx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dualdataset = False\n",
        "\n",
        "X_train_flat = df_X_train[['gradient','slp','surge1_input','surge2_input']].apply(flatten_array, axis=1)"
      ],
      "metadata": {
        "id": "3ftAVgr_ROB7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dual Model Dataset Prep"
      ],
      "metadata": {
        "id": "Ijh715HMtpc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dualdataset = True\n",
        "\n",
        "X_train1 = df_X_train.drop(['t_surge2_output','surge2_input','t_surge2_input'], axis=1).copy()\n",
        "X_train1_flat = X_train1.apply(flatten_array, axis=1)\n",
        "X1 = X_train1_flat.to_numpy()\n",
        "\n",
        "X_train2 = df_X_train.drop(['t_surge1_output','surge1_input','t_surge1_input'], axis=1).copy()\n",
        "X_train2_flat = X_train2.apply(flatten_array, axis=1)\n",
        "X2 = X_train2_flat.to_numpy()"
      ],
      "metadata": {
        "id": "G_i4v_7b8Mj1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train1 = Y_train.filter(regex='^surge1')\n",
        "y1 = Y_train1.to_numpy()\n",
        "\n",
        "Y_train2 = Y_train.filter(regex='^surge2')\n",
        "y2 = Y_train2.to_numpy()"
      ],
      "metadata": {
        "id": "mxAMAFT177k6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## X-Test Dataset Prep"
      ],
      "metadata": {
        "id": "A79RKOsvrKS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the data processing work done on the X-train dataset, repeated for X-test."
      ],
      "metadata": {
        "id": "rw3zzr8lrqFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_test['t_slp'] = df_X_test['t_slp'].apply(lambda x: np.array([timestamp_to_datetime(t) for t in x]))\n",
        "df_X_test['t_surge1_input'] = df_X_test['t_surge1_input'].apply(lambda x: np.array([timestamp_to_datetime(t) for t in x]))\n",
        "df_X_test['t_surge2_input'] = df_X_test['t_surge2_input'].apply(lambda x: np.array([timestamp_to_datetime(t) for t in x]))\n",
        "df_X_test['t_surge1_output'] = df_X_test['t_surge1_output'].apply(lambda x: np.array([timestamp_to_datetime(t) for t in x]))\n",
        "df_X_test['t_surge2_output'] = df_X_test['t_surge2_output'].apply(lambda x: np.array([timestamp_to_datetime(t) for t in x]))\n",
        "\n",
        "df_X_test['startingdate'] = df_X_test['t_slp'].apply(lambda x: get_nth_day(x))\n",
        "df_X_test['lastdate'] = df_X_test['t_slp'].apply(lambda x: get_last_date(x))\n",
        "df_X_test['year'] = df_X_test['t_slp'].apply(lambda x: get_first_year(x))\n",
        "df_X_test['t_slp'] = df_X_test['t_slp'].apply(lambda x: extract_hour(x))\n",
        "df_X_test['t_surge1_input'] = df_X_test['t_surge1_input'].apply(lambda x: extract_hour(x))\n",
        "df_X_test['t_surge2_input'] = df_X_test['t_surge2_input'].apply(lambda x: extract_hour(x))\n",
        "df_X_test['t_surge1_output'] = df_X_test['t_surge1_output'].apply(lambda x: extract_hour(x))\n",
        "df_X_test['t_surge2_output'] = df_X_test['t_surge2_output'].apply(lambda x: extract_hour(x))"
      ],
      "metadata": {
        "id": "GKldEWQTrJgY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_test['gradient'] = df_X_test['slp'].apply(calculate_gradients)"
      ],
      "metadata": {
        "id": "LWpdcgWnY8x7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler() \n",
        "for i, row in df_X_test['slp'].items():\n",
        "    # Scale each numpy array in the row\n",
        "    scaled_array = np.array([scaler.fit_transform(arr) for arr in row])\n",
        "    \n",
        "    # Update the dataframe column with the scaled values\n",
        "    df_X_test.at[i, 'slp'] = scaled_array\n",
        "\n",
        "scaler = MinMaxScaler() \n",
        "for i, row in df_X_test['gradient'].items():\n",
        "    # Scale each numpy array in the row\n",
        "    scaled_array = np.array([scaler.fit_transform(arr) for arr in row])\n",
        "    \n",
        "    # Update the dataframe column with the scaled values\n",
        "    df_X_test.at[i, 'gradient'] = scaled_array"
      ],
      "metadata": {
        "id": "iiWV74wZYSTW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_test['slp'] = df_X_test['slp'].apply(lambda arr: np.concatenate(arr).ravel())\n",
        "df_X_test['gradient'] = df_X_test['gradient'].apply(lambda arr: np.concatenate(arr).ravel())"
      ],
      "metadata": {
        "id": "IIPXjILlYqyz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if dualdataset == True:\n",
        "  X_test1 = df_X_test.drop(['t_surge2_output','surge2_input','t_surge2_input'], axis=1).copy()\n",
        "  X_test1_flat = X_test1.apply(flatten_array, axis=1)\n",
        "  X1_test = X_test1_flat.to_numpy()\n",
        "\n",
        "  X_test2 = df_X_test.drop(['t_surge1_output','surge1_input','t_surge1_input'], axis=1).copy()\n",
        "  X_test2_flat = X_test2.apply(flatten_array, axis=1)\n",
        "  X2_test = X_test2_flat.to_numpy()\n",
        "\n",
        "\n",
        "else:\n",
        "  X_test_flat = df_X_test[['gradient','slp','surge1_input','surge2_input']].apply(flatten_array, axis=1)\n",
        "  length = 20\n",
        "  X_test_flat1 = X_test_flat.head(1)\n",
        "  X_test_flat2 = X_test_flat.tail(1)"
      ],
      "metadata": {
        "id": "XSjDX63-72Gb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Model"
      ],
      "metadata": {
        "id": "sJI6X5nHgObG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train1 = pd.DataFrame()\n",
        "Y_train2 = pd.DataFrame()\n",
        "\n",
        "for index, row in Y_train.iterrows():\n",
        "    surge1_values = row.loc[row.index.str.startswith('surge1')].values\n",
        "    surge2_values = row.loc[row.index.str.startswith('surge2')].values\n",
        "    \n",
        "    Y_train1 = Y_train1.append(pd.Series(surge1_values), ignore_index=True)\n",
        "    Y_train2 = Y_train2.append(pd.Series(surge2_values), ignore_index=True)"
      ],
      "metadata": {
        "id": "VQJx8Pi6wCrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "id": "Nfqil2-MD8EQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=hp.Int('units_1', min_value=32, max_value=128, step=32),\n",
        "                    activation='relu', input_shape=(134500,)))\n",
        "    model.add(Dense(units=hp.Int('units_2', min_value=32, max_value=128, step=32),\n",
        "                    activation='relu'))\n",
        "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "    model.add(Dense(units=hp.Int('units_3', min_value=16, max_value=64, step=16),\n",
        "                    activation='relu'))\n",
        "    model.add(Dense(10, activation='linear', name='Output'))\n",
        "\n",
        "    # Optimizer options\n",
        "    optimizer_type = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    # Set the optimizer based on the selected type\n",
        "    if optimizer_type == 'adam':\n",
        "        optimizer = optimizers.Adam(learning_rate=hp_learning_rate)\n",
        "    elif optimizer_type == 'rmsprop':\n",
        "        optimizer = optimizers.RMSprop(learning_rate=hp_learning_rate)\n",
        "    elif optimizer_type == 'sgd':\n",
        "        optimizer = optimizers.SGD(learning_rate=hp_learning_rate)\n",
        "\n",
        "    stop_early = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "hu7fHgNH5Z7Y"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_testing(original_df, y_dataset):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(original_df, y_dataset, test_size=0.2, random_state=42)\n",
        "    tuner = RandomSearch(\n",
        "        build_model,\n",
        "        objective='val_loss',\n",
        "        max_trials=2,\n",
        "        executions_per_trial=1,\n",
        "        directory='rnn_randomsearch',\n",
        "        project_name='tideprediction'\n",
        "    )\n",
        "    tuner.search(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=16)\n",
        "    results_summary = tuner.results_summary()\n",
        "    print(results_summary)\n",
        "    best_model = tuner.get_best_models(num_models=1)[0]\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "tblMX8o-5dtY"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_predict(model, X_train, Y_train, X_test):\n",
        "    model.fit(X_train, Y_train, epochs=20, batch_size=16)\n",
        "    predictions = model.predict(X_test)\n",
        "    predictions_df = pd.DataFrame(predictions)\n",
        "    predictions_df.index = X_train.index\n",
        "    predictions_df.columns = Y_train.columns\n",
        "    return predictions_df\n",
        "\n",
        "from keras_visualizer import visualizer\n",
        "\n",
        "# Splitting the data and training/testing for location 1\n",
        "location1_X_train, location1_X_test, location1_Y_train, location1_Y_test = train_test_split(X_train_flat, Y_train1, test_size=0.2, random_state=42)\n",
        "location1_model = model_testing(location1_X_train, location1_Y_train)\n",
        "visualizer(location1_model, file_format='png', view=True)\n",
        "\n",
        "# Splitting the data and training/testing for location 2\n",
        "location2_X_train, location2_X_test, location2_Y_train, location2_Y_test = train_test_split(X_train_flat, Y_train2, test_size=0.2, random_state=42)\n",
        "location2_model = model_testing(location2_X_train, location2_Y_train)\n",
        "plot_model(location2_model, to_file='location2_model.png',show_layer_activations=True,show_layer_names=True,show_shapes=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7kLrx5po3fbL",
        "outputId": "ff5833cb-9547-4e3c-c8bd-5a986764998b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in rnn_randomsearch/tideprediction\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_loss\", direction=\"min\")\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "units_1: 128\n",
            "units_2: 64\n",
            "dropout_rate: 0.2\n",
            "units_3: 48\n",
            "learning_rate: 0.001\n",
            "Score: 0.593422532081604\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "units_1: 128\n",
            "units_2: 64\n",
            "dropout_rate: 0.30000000000000004\n",
            "units_3: 32\n",
            "learning_rate: 0.001\n",
            "Score: 0.6784546375274658\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "units_1: 128\n",
            "units_2: 64\n",
            "dropout_rate: 0.4\n",
            "units_3: 16\n",
            "learning_rate: 0.001\n",
            "Score: 0.6883165836334229\n",
            "\n",
            "Trial 07 summary\n",
            "Hyperparameters:\n",
            "units_1: 32\n",
            "units_2: 128\n",
            "dropout_rate: 0.30000000000000004\n",
            "units_3: 48\n",
            "learning_rate: 0.001\n",
            "Score: 0.7232275605201721\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "units_1: 96\n",
            "units_2: 96\n",
            "dropout_rate: 0.4\n",
            "units_3: 64\n",
            "learning_rate: 0.001\n",
            "Score: 0.7289102673530579\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "units_1: 32\n",
            "units_2: 64\n",
            "dropout_rate: 0.4\n",
            "units_3: 32\n",
            "learning_rate: 0.001\n",
            "Score: 0.7333300709724426\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "units_1: 96\n",
            "units_2: 128\n",
            "dropout_rate: 0.30000000000000004\n",
            "units_3: 32\n",
            "learning_rate: 0.001\n",
            "Score: 0.7497830986976624\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "units_1: 128\n",
            "units_2: 32\n",
            "dropout_rate: 0.30000000000000004\n",
            "units_3: 48\n",
            "learning_rate: 0.001\n",
            "Score: 0.7533013820648193\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "units_1: 64\n",
            "units_2: 96\n",
            "dropout_rate: 0.4\n",
            "units_3: 48\n",
            "learning_rate: 0.01\n",
            "Score: 0.7568062543869019\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "units_1: 32\n",
            "units_2: 64\n",
            "dropout_rate: 0.30000000000000004\n",
            "units_3: 32\n",
            "learning_rate: 0.0001\n",
            "Score: 0.807858943939209\n",
            "None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-5785062acbf2>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Splitting the data and training/testing for location 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlocation1_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation1_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation1_Y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation1_Y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlocation1_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation1_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation1_Y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation1_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-b437ee65c2ee>\u001b[0m in \u001b[0;36mmodel_testing\u001b[0;34m(original_df, y_dataset)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mresults_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mget_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \"\"\"\n\u001b[1;32m    365\u001b[0m         \u001b[0;31m# Method only exists in this class for the docstring override.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_deepcopy_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36mget_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \"\"\"\n\u001b[1;32m    363\u001b[0m         \u001b[0mbest_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_trials\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \"\"\"\n\u001b[1;32m    363\u001b[0m         \u001b[0mbest_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_trials\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Reload best checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# Only load weights to avoid loading `custom_objects`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_try_build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;31m# Stop if `build()` does not return a valid model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_hypermodel\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmaybe_distribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_override_compile_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-69c9e860d943>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Set the optimizer based on the selected type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptimizer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhp_learning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moptimizer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhp_learning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def file_processing(combined_df):\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    preds_file_path = f'output_{timestamp}.csv'\n",
        "    combined_df.to_csv(preds_file_path)\n",
        "\n",
        "# Combine the predictions into a single DataFrame\n",
        "combined_df = pd.concat([location1_predictions, location2_predictions], axis=1)\n",
        "\n",
        "# Rearrange the columns\n",
        "combined_df = combined_df.reindex(columns=sorted(combined_df.columns))\n",
        "\n",
        "# Save the combined predictions to a file\n",
        "file_processing(combined_df)"
      ],
      "metadata": {
        "id": "JUW6aje7Burb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model - RegressorChain"
      ],
      "metadata": {
        "id": "7PiyAfzZ_CA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multioutput import RegressorChain\n",
        "\n",
        "regressor1 = xgb.XGBRegressor(objective='reg:squarederror', tree_method='gpu_hist', gpu_id=0)\n",
        "chained_regressor1 = RegressorChain(regressor1,random_state=42).fit(X1, y1)\n",
        "\n",
        "regressor2 = xgb.XGBRegressor(objective='reg:squarederror', tree_method='gpu_hist', gpu_id=0)\n",
        "chained_regressor2 = RegressorChain(regressor2,random_state=42).fit(X2, y2)"
      ],
      "metadata": {
        "id": "IM1Ali5__EBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Define the filename for saving the model\n",
        "filename = 'chained_regressor2_model.joblib'\n",
        "\n",
        "# Save the model to the file\n",
        "joblib.dump(chained_regressor2, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB_i2EBXYZ3Z",
        "outputId": "7db48541-f11d-471d-d7fe-4a25ca242eb1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chained_regressor2_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions1 = chained_regressor1.predict(X1_test)\n",
        "\n",
        "predictions2 = chained_regressor2.predict(X2_test)"
      ],
      "metadata": {
        "id": "QW-b_55x_vy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions1_df = pd.DataFrame(predictions1)\n",
        "predictions1_df.index = X_train1_flat.index\n",
        "predictions1_df.columns = Y_train1.columns\n",
        "\n",
        "predictions2_df = pd.DataFrame(predictions2)\n",
        "predictions2_df.index = X_train2_flat.index\n",
        "predictions2_df.columns = Y_train2.columns"
      ],
      "metadata": {
        "id": "Yml0s1NfAUyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns1 = predictions1_df.columns\n",
        "columns2 = predictions2_df.columns\n",
        "\n",
        "# Combine the DataFrames with the desired column order\n",
        "combined_df = pd.DataFrame()\n",
        "\n",
        "for col1, col2 in zip(columns1, columns2):\n",
        "    combined_df[col1] = predictions1_df[col1]\n",
        "    combined_df[col2] = predictions2_df[col2]"
      ],
      "metadata": {
        "id": "cISFjfduBWdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fileprocessing(combined_df):\n",
        "  timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "  preds_file_path = f'output_{timestamp}.csv'\n",
        "  combined_df.to_csv(preds_file_path)"
      ],
      "metadata": {
        "id": "O8CqzGrCPJVx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fileprocessing(combined_df)"
      ],
      "metadata": {
        "id": "kgNIwfiRYNjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model - MultiOutputRegressor\n"
      ],
      "metadata": {
        "id": "8cwOQ4mxxIRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = xgb.XGBRegressor(objective='reg:squarederror', tree_method='gpu_hist', gpu_id=0)\n",
        "multioutput_regressor = MultiOutputRegressor(regressor).fit(X, y)"
      ],
      "metadata": {
        "id": "oNzzvzPAI8r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for the grid search\n",
        "param_grid = {\n",
        "    'estimator__learning_rate': [0.1, 0.2],\n",
        "    'estimator__max_depth': [3, 5],\n",
        "    'estimator__n_estimators': [100, 200]\n",
        "}\n",
        "\n",
        "# Create the XGBoost regressor with GPU settings\n",
        "regressor = xgb.XGBRegressor(objective='reg:squarederror', tree_method='gpu_hist', gpu_id=0)\n",
        "\n",
        "# Create the MultiOutputRegressor with XGBoost regressor\n",
        "multioutput_regressor = MultiOutputRegressor(regressor)\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(multioutput_regressor, param_grid, cv=3)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)"
      ],
      "metadata": {
        "id": "Tp9m5d8raes3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "model_file_path = f'model_{timestamp}.pkl'\n",
        "\n",
        "joblib.dump(multioutput_regressor, model_file_path)"
      ],
      "metadata": {
        "id": "3PCJbxhm4dnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = multioutput_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "imsa65NmF8St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_regressor = multioutput_regressor.regressor_\n",
        "\n",
        "# Get model information\n",
        "model_info = xgb_regressor.get_booster().get_dump()\n",
        "\n",
        "# Print the model information\n",
        "for tree_idx, tree_info in enumerate(model_info):\n",
        "    print(f\"Tree {tree_idx}:\\n{tree_info}\")"
      ],
      "metadata": {
        "id": "2di2Tex3r_ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y Testing Processing and File Save"
      ],
      "metadata": {
        "id": "k1oF1y_7iaWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fileprocessing(preds):\n",
        "  timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "  preds_file_path = f'output_{timestamp}.csv'\n",
        "  output_df = pd.DataFrame(preds)\n",
        "  output_df.index = df_test_flat.index\n",
        "  output_df.columns = Y_train.columns\n",
        "  output_df.to_csv(preds_file_path)"
      ],
      "metadata": {
        "id": "C7z1LOjnk8zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fileprocessing(predictions)"
      ],
      "metadata": {
        "id": "z5w9gCOqlMW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Notes"
      ],
      "metadata": {
        "id": "oWfD5MI8sPgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab Pro is invaluable on a dataset of this size.\n",
        "\n",
        "\n",
        "When using this implementation:\n",
        "\n",
        "```\n",
        "regressor = xgb.XGBRegressor(objective='reg:squarederror', tree_method='gpu_hist', gpu_id=0)\n",
        "multioutput_regressor = MultiOutputRegressor(regressor).fit(X, y)\n",
        "```\n",
        "\n",
        "**230 seconds** | When using 'gpu_hist' and 1000 row subset of data\n",
        "\n",
        "**675 seconds** | When using 'gpu_hist' and entire data set\n",
        "\n",
        "\n",
        "**Stopped at 7,402 seconds** | When using standard runtime and 1000 row subset  of data\n",
        "\n",
        "**Session crashes** | When using standard runtime and entire data set\n",
        "\n",
        "\n",
        "Parallel trees not used in this example but could potentially quicken the model training\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cS193M0VsYxU"
      }
    }
  ]
}